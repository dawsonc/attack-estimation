{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Networks for Estimating Attack Vector\n",
    "\n",
    "## Intro & motivating example\n",
    "\n",
    "Humans are notoriously bad at reasoning about probabilities: more often than not, we rely on cognitive shortcuts (heuristics and biases) instead of actually calculating the liklihood of events. This can be a good thing; just think how paralyzed we would be if we stopped to calculate the probability of rain every time we heard raindrops on our window, rather than just grabbing an umbrella! Even computers can start to run into tractability problems when working with probability distributions involving even a few dozen variables. In this tutorial, we will introduce a tool, called Bayesian networks, for automatically and efficiently reasoning about probabilities. These networks will allow us to ask questions like \"given this new evidence, what is the probability of some hidden variable being true\" or \"what is the most likely explanation for some set of observations?\". These questions might remind you of our lectures on Hidden Markov Models (HMMs); it turns out that Bayesian networks can be used to represent Markov processes, but they are much more expressive and can be used to model much more complicated scenarios.\n",
    "\n",
    "To make this discussion more concrete, it's helpful to have a motivating example. You are a security engineer in the employ of the Generic Galactic Empire aboard a controversial new ~~moon~~ space station. You are aware of several security vulnerabilities in the space station's software subsystems, but you have no way to detect whether those vulnerabilities are being exploited except by running diagnostics on various workstations throughout the station. Since you'd like to be able to detect attacks based on the probability that a vulnerability is being exploited, you'd like an easy way to relate your observations of workstations to the probability of a cyberattack taking place. After a brief review of probability fundamentals, we'll discuss how Bayesian networks can be used to model this situation and make inferences automatically.\n",
    "\n",
    "### References\n",
    "The discussion in this tutorial draws heavily from the following sources:\n",
    "- Russell & Norvig, AIMA, Chapter 13 & 14\n",
    "- [R. Dechter, \"Bucket Elimination: A Unifying Framework for Probabilistic Inference\"](https://webdocs.cs.ualberta.ca/~rgreiner/C-366/RG-2002-SLIDES/BucketElim.pdf) \n",
    "\n",
    "Chapter 13 of AIMA provides an overview of probability fundamentals, while chapter 14 discusses Bayesian networks in more depth. Dechter's article describes efficient algorithms for making inference based on Bayesian networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Review\n",
    "- This section won't provide a huge overview of probability, but just a reminder of the relevant parts.\n",
    "- Random variables and joint probability distributions (for n binary variables, requires 2^n storage)\n",
    "- Reasoning using joint distributions (13.3)\n",
    "    - just read out e.g. P(A ^ B)\n",
    "    - marginalization to get marginal probability e.g. just P(A) = P(A ^ B) + P(A ^ !B) (plus general eq.)\n",
    "    - Conditional/posterior probabilities, product rule P(A ^ B) = P(A | B)P(B), and conditioning (marginalization but with conditional probs).\n",
    "    - Derive P(X|e) = P(X^e)/P(e) = aP(X^e) = a \\sum_y P(X, e, y) (normalization to get a so that P(X|e)+P(!X|e)=1\n",
    "    - Remark: this would allow us to answer whatever queries we want to ask just by looking in the joint distribution table. BUT that table has size O(2^n) and requires O(2^n) to process by summing over it.\n",
    "- Reasoning using conditional distributions (13.4)\n",
    "    - Lots of redundant information in full joint distribution (like how your toothache affects the weather, ignoring causality)\n",
    "    - Independence! Conditional independence (based on causality)!\n",
    "    - Allows factoring the joint distribution into multiple smaller conditional distributions, saving on size. 2^n+2^m << 2^{n+m}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Networks\n",
    "\n",
    "Exploiting conditional independence can allow us to reason much more efficiently about joint probabilities, but it would be really nice if we could automate the inference process by encoding conditional probabilities in a convenient data structure. Since dependence relates each variable to a set of \"parent\" variables, a natural structure is a directed graph, where\n",
    "- Each node corresponds to an uncertain variable (in this tutorial, we'll restrict ourselves to discrete random variables),\n",
    "- If variable $B$ is dependent on $A$, then we draw a directed edge from node `A` to node `B` in the graph, and\n",
    "- Each node $X$ is labelled with its conditional probability distribution $P(X\\ |\\ \\text{Parents}(X))$, which takes the form of a table with a row for each combination of assignments to the parent variables of $X$, specifying the probabilities that $X$ takes on each of its values conditioned on those parent variable assignments.\n",
    "\n",
    "Since we don't want any variable to depend (directly or indirectly) on itself, this graph must not have any directed cycles (making it a *directed acyclic graph*. An example graph is shown in the figure below. Given this structure, we can see that it directly encodes both independence and conditional independence: sibling nodes (i.e. nodes sharing a parent) are conditionally independent, while nodes in disconnected graphs are independent.\n",
    "\n",
    "We call this data structure a Bayesian network (or sometimes a *belief network* or *causal network*). These networks can represent any full joint distribution, but depending on the degree to which causal relationships allow us to factor the joint distribution into smaller conditional distributions, Bayesian networks can encode this information much more compactly. In the next example, we'll give a simple example of a Bayesian network and show how we can make inference based on these networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple example\n",
    "\n",
    "Before moving on to the more complicated case of our original motivating problem, we'll use the simpler scenario from Fig. 14.2 in Russel & Norvig to illustrate the key features of Bayesian networks. In this scenario, you've just installed a new alarm in your house, and since you don't want Google spying on your home, you've chosen not to connect the alarm to the internet. Instead, you've asked your neighbors, John and Mary, to listen for the alarm and call you if they hear it going off. Complicating matters, the alarm will go off if a burglary occurs, but it is a little too sensitive and will also go off if an earthquake occurs. In addition, John will will sometimes confuse a telephone ringing for the alarm and call then as well, and because Mary likes listening to loud music, she will sometimes miss the alarm altogether.\n",
    "\n",
    "In this scenario, we essentially have five uncertain boolean variables:\n",
    "+ `B`: whether a burglary has occurred,\n",
    "+ `E`: whether an earthquake has occurred,\n",
    "+ `A`: whether the alarm has gone off,\n",
    "+ `J`: whether John calls you, and\n",
    "+ `M`: whether Mary calls you.\n",
    "\n",
    "Note that only `J` and `M` are observable. If we were to encode the full joint probability distribution, we'd need to store a table of size $O(2^n) = O(32)$. This is not too large in thi scase, but if you have even 30 variables then the joint distribution table would require $O(4$ GB$)$ of storage, and adding a 31st variable would require another 4 GB! We are clearly on the wrong side of this exponential when it comes to the joint distribution.\n",
    "\n",
    "To make the problem more tractable, we can exploit the causal relationships between these variables, allowing us to store a handful of smaller conditional distributions rather than a monolithic joint distribution. The causal structure of this problem leads to the Bayesian network shown in the image below (reprinted from Russell & Norvig):\n",
    "\n",
    "<img src=\"files/figs/alarm-problem-structure.png\">\n",
    "\n",
    "Since `J` and `M` only depend on `A`, we don't need to explicitly store the effect of an earthquake on the probability of John calling. Instead of a 32-entry joint distribution, we only need to store 20 values in 5 smaller conditional distributions. Only 10 entries are shown here because for boolean variables the probability of a false value is fixed at 1-(the probability of a true value). For scenarios with even more variables, these savings would be even more dramatic.\n",
    "\n",
    "It's important to note that the Bayesian network representation is not unique: you can order the variables in any way you want and back out the conditional probability tables from the joint distribution. In this case, we have ordered the nodes from causes to effects (causes at the top, flowing down to effects at the bottom of the network). This is a good heuristic for constructing concise Bayesian networks.\n",
    "\n",
    "We've written classes in `bayes_net.py` implementing the basic functionality of Bayesian networks for you, allowing you to represent these networks programmatically. You should go check out the source code to get an idea of what features are available, and a basic example of constructing a network for this example scenario is given below. To properly load the drawing function, **you must run this cell twice**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have 5 nodes and 4 edges\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Example code for constructing the simple burglary example from AIMA (Fig. 14.2)\n",
    "from bayes_net import BayesNet, BayesNode\n",
    "import numpy as np\n",
    "\n",
    "# First, instantiate the two nodes that have no parents in the network.\n",
    "# The domain of these variables is just {True, False} here, but we support arbitrary discrete domains\n",
    "burglary_node = BayesNode('Burglary')\n",
    "burglary_node.set_marginal_distribution({True: 0.001, False: 0.999})\n",
    "earthquake_node = BayesNode('Earthquake')\n",
    "earthquake_node.set_marginal_distribution({True: 0.002, False: 0.998})\n",
    "\n",
    "# Now we can instantiate nodes with probabilities conditioned on their parents\n",
    "# We have to build the conditional distribution table one entry at a time, for each combination\n",
    "# of parent variables\n",
    "alarm_node = BayesNode('Alarm')\n",
    "alarm_node.add_entry([(burglary_node, True), (earthquake_node, True)], {True: 0.95, False: 0.05})\n",
    "alarm_node.add_entry([(burglary_node, True), (earthquake_node, False)], {True: 0.94, False: 0.06})\n",
    "alarm_node.add_entry([(burglary_node, False), (earthquake_node, True)], {True: 0.29, False: 0.71})\n",
    "alarm_node.add_entry([(burglary_node, False), (earthquake_node, False)], {True: 0.001, False: 0.999})\n",
    "\n",
    "john_node = BayesNode('John')\n",
    "john_node.add_entry([(alarm_node, True)], {True: 0.9, False: 0.1})\n",
    "john_node.add_entry([(alarm_node, False)], {True: 0.05, False: 0.95})\n",
    "\n",
    "mary_node = BayesNode('Mary')\n",
    "mary_node.add_entry([(alarm_node, True)], {True: 0.7, False: 0.3})\n",
    "mary_node.add_entry([(alarm_node, False)], {True: 0.01, False: 0.99})\n",
    "\n",
    "# Now we can create a BayesNet object to store all the nodes.\n",
    "alarm_net = BayesNet([burglary_node, earthquake_node, alarm_node, john_node, mary_node])\n",
    "\n",
    "# As a sanity check, we can visualize the network to make sure it matches our model above.\n",
    "# This visualization is auto-generated, so it will be a bit messy, but we can still see\n",
    "# the overall structure of the network.\n",
    "alarm_net.draw_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Bayesian Networks\n",
    "\n",
    "Now that we've constructed a bayesian network, what can we do with it? First of all, we can use the network to query the full joint probability distribution as well as asking other questions based on joint probabilities.\n",
    "\n",
    "#### Calculating Joint Probabilities\n",
    "\n",
    "In general, the joint probability for variable assignments $x_1,\\ldots, x_n$ is given by\n",
    "\n",
    "$$P(x_1,\\ldots, x_n) = \\prod_{i=1}^n P(x_i\\ |\\ \\text{Parents}(x_i))$$\n",
    "\n",
    "where we can simply read $P(x_i\\ |\\ \\text{Parents}(x_i)$ out of the conditional distribution attached to node `x_i`. In the context of our specific example, say we want to know the probability `B = True`, `E = False`, `A = True`, `J = True`, `M = True` (the probability that we got a call from John and Mary, the alarm has gone off, there has been a burglary, and there has been no earthquake). Using the general formula above, we get this joint probability as:\n",
    "\n",
    "$$\\begin{align*}\n",
    "P(M, J, A, not E, B) &= P(M | A) \\cdot P(J |A) \\cdot P(A | not E, B) \\cdot P(not E) \\cdot P(B) \\\\\n",
    "                     &= 0.7 \\cdot 0.9 \\cdot 0.94 \\cdot 0.998 \\cdot 0.001 \\\\\n",
    "                     &= 0.00059\n",
    "\\end{align*}$$\n",
    "\n",
    "This functionality is implemented in the provided `BayesNet` class, which we can query directly as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(M, J, A, not E, B) = 0.0005910156\n"
     ]
    }
   ],
   "source": [
    "joint_prob = alarm_net.calc_joint([(mary_node, True), \n",
    "                                   (john_node, True),\n",
    "                                   (alarm_node, True),\n",
    "                                   (earthquake_node, False),\n",
    "                                   (burglary_node, True)])\n",
    "print('P(M, J, A, not E, B) = {}'.format(joint_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Posterior Probabilities\n",
    "\n",
    "With this ability to query the joint distribution, we can answer a broad range of other questions. For instance, if we want to know the posterior probability of some event $X$ after observing some evidence $e$, we can calculate\n",
    "\n",
    "$$P(X|e) = \\alpha P(X, e) = \\alpha \\sum_{y \\notin \\{X,e\\}} P(X, e, y)$$\n",
    "\n",
    "where $\\alpha$ is a normalization constant set so that $P(X|e) + P(not X|e) = 1$. In our example, if we want to know the probability of a burglary having occured if we receive a call from John and Mary, we can calculate\n",
    "\n",
    "$$\\begin{align*}\n",
    "P(B|J, M) = \\alpha P(B, J, M) &= \\alpha \\sum_{a \\in \\{A, not A\\}}\\sum_{e \\in \\{E, notE\\}} P(B, J, M, a, b, e)\n",
    "\\end{align*}$$\n",
    "\n",
    "where $P(B, J, M, a, b, e)$ is a joint probability calculated as shown above. Substituting the equation for joint probabilities into this expression, we get \n",
    "\n",
    "$$\\begin{align*}\n",
    "P(B | J, M) = \\alpha P(B, J, M) &= \\alpha \\sum_{a \\in \\{A, not A\\}} \\sum_{e \\in \\{E, notE\\}} P(B, J, M, a, B, e) \\\\\n",
    "                              &= \\alpha \\sum_{a \\in \\{A, not A\\}}\\sum_{e \\in \\{E, notE\\}} P(M | a) \\cdot P(J | a) \\cdot P(a | e, B) \\cdot P(e) \\cdot P(B)\n",
    "\\end{align*}$$\n",
    "\n",
    "This is a convenient feature, but without further optimization it is pretty inefficient: we need to multiply $n$ values for each of $2^n$ combinations of variable assignments, so this method has time complexity $O(n2^n)$, which again puts us on the losing side of an exponential term. We've implemented this brute-force algorithm (as described in AIMA 14.4.1) in the cell below. You can see how it performs on the simple network we've defined above; later, we'll benchmark the performance of this algorithm compared to more efficient algorithms when run on larger networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"false\": {},\n",
      "    \"true\": {}\n",
      "}\n",
      "[(True,), (False,)]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def init_distribution(X):\n",
    "    \"\"\"Returns an empty distribution in the form of a nested dictionary, where level i\n",
    "    has keys corresponding to values of variable x_i in X, along with a list of\n",
    "    discrete combinations represented in P\"\"\"\n",
    "    P = dict()\n",
    "    domain_combinations = list(itertools.product(*[list(var.domain) for var in X]))\n",
    "    # this loop constructs a series of nested dictionaries, where each level corresponds\n",
    "    # to a variable in X\n",
    "    for assignments in domain_combinations:\n",
    "        previous_level = P\n",
    "        for val in assignments:\n",
    "            if val not in previous_level:\n",
    "                next_level = dict()\n",
    "                previous_level[val] = next_level\n",
    "                previous_level = next_level\n",
    "            else:\n",
    "                previous_level = previous_level[val]\n",
    "    return P, domain_combinations\n",
    "\n",
    "def update(distribution, assignment, value):\n",
    "    \"\"\"Updates the value for the given assignment in the nested dictionary distribution\"\"\"\n",
    "    head = assignment[0]\n",
    "    if type(distribution[head]) is not dict:\n",
    "        distribution[head] = value\n",
    "    else:\n",
    "        update(distribution[head], assignment[1:], value)\n",
    "\n",
    "def brute_force_query(X, e, net):\n",
    "    \"\"\"Returns the posterior probability P(x | e) using the Bayesian network `net`,\n",
    "    using a brute force enumeration method with time complexity O(n2^n), where\n",
    "    n is the number of variables in the network.\n",
    "    \n",
    "    Inputs:\n",
    "        X: a list of nodes for which we will calculate posteriors\n",
    "        e: a list of tuples (node, value) specifying assignments to evidence variables\n",
    "            (we assume that e and X are disjoint)\n",
    "    Outputs:\n",
    "        P: a distribution over the query variables in X\n",
    "    \"\"\"\n",
    "    # initialize distribution for each value in the domains of the variables in X \n",
    "    P, X_assignments = init_distribution(X)\n",
    "    \n",
    "    # get the list of variables not in X or e\n",
    "    e_vars = [var[0] for var in e]\n",
    "    Y = [node for node in net.nodes if node not in X and node not in e_vars]\n",
    "    \n",
    "    # now we need to calculate the conditional probability for each possible assignment in P\n",
    "    for assignment in X_assignments:\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "X = [burglary_node]\n",
    "e_vars = [john_node, mary_node]\n",
    "P, dc = init_distribution(X)\n",
    "print(json.dumps(P, sort_keys=True, indent=4))\n",
    "net = alarm_net\n",
    "y = [node for node in net.nodes if node not in X and node not in e_vars]\n",
    "\n",
    "print(list(itertools.product(*[list(var.domain) for var in X])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What can they do for you (with reference to the simple example)?\n",
    "    - Answer queries on the joint probability distribution e.g. P(a, b, !c, d, !e) = \\product_i P(x_i | parents(x_i))\n",
    "    - Query the posterior given evidence e.g. P(X | e) = aP(X, e) = a \\sum_{y not x not e} P(X, e, y) <- same as above\n",
    "    - MAP: max liklihood explanation, the X with the highest probability given e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute Force Method\n",
    "- Describe brute-force method for getting probability estimates\n",
    "    - 14.4.1\n",
    "    - O(n2^n) for n vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- benchmark the brute force algorithm to show how exponential it is\n",
    "    - Simple example from last section\n",
    "    - Star wars example from this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run brute_force_query on the two examples to see how long they take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Simple speedup via DFS enumeration-ask alg from book fig 14.9\n",
    "    - Explain how it works\n",
    "    - Still super slow: O(2^n) for n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CITE: Russel & Norvig AIMA Ch 14, Section 4, Fig. 14.9\n",
    "def simple_query(X, e, net):\n",
    "    \"\"\"Returns the posterior probability P(x | e) using the Bayesian network `net`,\n",
    "    using an improved enumeration method with time complexity O(2^n), where n is\n",
    "    the number of variables in the network, using analogue to depth-first search.\n",
    "    \n",
    "    Inputs:\n",
    "        X: a list of variable names for which we will calculate posteriors\n",
    "        e: a list of tuples (name, value) specifying assignments to evidence variables\n",
    "            (we assume that e and X are disjoint)\n",
    "    Outputs:\n",
    "        P: a distribution over the query variables in X (a dict mapping names in\n",
    "           X to a probability value)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def enumerate_all(variables, e):\n",
    "    \"\"\"Computes one step in the depth-first iteration of the Bayesian network\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- benchmark the simple algorithm to show how it performs better than the brute force method\n",
    "    - Simple example from last section\n",
    "    - Star wars example from this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simple_force_query on the two examples to see how long they take"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucket Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the main notebook to run.\n",
    "# In this notebook, we go through the \"attack-estimation\" portion of the project.\n",
    "# Some utility code, including base classes, lives in files outside this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bunch of imports\n",
    "from bayes_net import BayesNet, BayesNode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024000000000000004\n",
      "Have 4 nodes and 3 edges\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain\n",
      "Sprinklers\n",
      "Grass\n",
      "Feet\n"
     ]
    }
   ],
   "source": [
    "# A demonstration for developers of how to create a BayesNet. In this example, I define the likelihood of getting\n",
    "# wet feet as a function of wet grass, which is a function of raining and sprinkling.\n",
    "\n",
    "# First, declare a bunch of nodes.\n",
    "rain_node = BayesNode('Rain')\n",
    "rain_node.set_marginal_distribution({True: 0.2, False: 0.8})\n",
    "sprinklers_node = BayesNode('Sprinklers')\n",
    "sprinklers_node.set_marginal_distribution({'on': 0.6, 'off': 0.4})\n",
    "grass_node = BayesNode('Grass')\n",
    "grass_node.add_entry([(rain_node, True), (sprinklers_node, 'on')], {'wet': 0.95, 'dry': 0.05})\n",
    "grass_node.add_entry([(rain_node, True), (sprinklers_node, 'off')], {'wet': 0.6, 'dry': 0.4})\n",
    "grass_node.add_entry([(rain_node, False), (sprinklers_node, 'on')], {'wet': 0.45, 'dry': 0.55})\n",
    "grass_node.add_entry([(rain_node, False), (sprinklers_node, 'off')], {'wet': 0.1, 'dry': 0.90})\n",
    "feet_node = BayesNode('Feet')\n",
    "feet_node.add_entry([(grass_node, 'wet')], {'dry': 0.1, 'damp': 0.5, 'drenched': 0.4})\n",
    "feet_node.add_entry([(grass_node, 'dry')], {'dry': 0.7, 'damp': 0.2, 'drenched': 0.1})\n",
    "\n",
    "# Second, create a BayesNet object that just stores all the nodes.\n",
    "net = BayesNet([rain_node, sprinklers_node, grass_node, feet_node])\n",
    "\n",
    "# Third, do whatever you want with this data structure, like ask for the conditional distribution for a variable.\n",
    "fetched_node = net.get_node('Feet')\n",
    "assert fetched_node == feet_node  # Just a sanity check\n",
    "# Calculate some joint probabilities\n",
    "joint_prob = net.calc_joint([(rain_node, True), (sprinklers_node, 'off'), (feet_node, 'damp'), (grass_node, 'wet')])\n",
    "print(joint_prob)\n",
    "\n",
    "# Fourth, visualize it all. Right now, visualization is crude (weird layout) but should be correct (arrows the right way.)\n",
    "net.draw_net()\n",
    "\n",
    "# Fifth, show off a fancy new topographical ordering method I just wrote.\n",
    "ordered_nodes = net.get_topographical_ordering()\n",
    "for node in ordered_nodes:\n",
    "    print(node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate Inference:\n",
    "\n",
    "So far in this notebook, we've stuck with relatively small nets and simple distributions. That means that doing exact inference - calculating analytically exactly what some distribution will look like - is possible. For a lot of problems that we care about, though, exact inference isn't possible. There are lots of reasons this might happen: some distribution is wonky and therefore can't be reasoned about analytically, a net is so complex that doing all the math to marginalize out variables seems impossible, etc.\n",
    "\n",
    "But we don't have to give up. In the following examples, we'll implement two sorts of approximate inference techniques: rejection sampling and Gibbs sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_evidence(node, value, evidence):\n",
    "    for evidence_name, evidence_value in evidence:\n",
    "        if node.name == evidence_name:\n",
    "            if value == evidence_value:\n",
    "                return True\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "# In this sampling method, we just generate random setups through sampling.\n",
    "# If we satisfy the evidence, we save the state; if we don't we reject the sample and keep trying.\n",
    "# After saving lots of states, the hope is that we have enough counts to estimate the frequencies of other variables\n",
    "# conditioned on the evidence.\n",
    "def rejection_sampling(X, e, net, num_samples=10000):\n",
    "    # For each of the variables in X, store a count of how often each value in the domain appears.\n",
    "    # Intialization to zero counts everywhere.\n",
    "    var_to_val_to_count = {}\n",
    "    for x in X:\n",
    "        var_to_val_to_count[x] = {}\n",
    "        for val in net.get_node(x).domain:\n",
    "            var_to_val_to_count[x][val] = 0\n",
    "    # Now, just generate tons of samples in the net, rejecting if it doesn't match the evidence.\n",
    "    num_rejects = 0\n",
    "    for sample_idx in range(num_samples):\n",
    "        # Get a topographical ordering to start sampling.\n",
    "        ordered_nodes = net.get_topographical_ordering()\n",
    "        assignments = {}\n",
    "        reject_sample = False\n",
    "        for node in ordered_nodes:\n",
    "            if node.marginal_distribution:\n",
    "                sample = node.draw_sample()\n",
    "                assignments[node] = sample\n",
    "            else:\n",
    "                parent_val_assignments = [(parent, assignments.get(parent)) for parent in node.parents]\n",
    "                sample = node.draw_sample(parent_vals=parent_val_assignments)\n",
    "                assignments[node] = sample\n",
    "            # Do the rejection part if the node that was sampled contradicts the evidence\n",
    "            if not matches_evidence(node, sample, e):\n",
    "                reject_sample = True\n",
    "                break\n",
    "        if reject_sample:\n",
    "            num_rejects += 1\n",
    "            continue\n",
    "        # Matched the evidence, so update the counts of valid variable assignments\n",
    "        for assigned_node, assigned_val in assignments.items():\n",
    "            if assigned_node.name in var_to_val_to_count.keys():\n",
    "                var_to_val_to_count[assigned_node.name][assigned_val] += 1\n",
    "    # At the end, finally have counts that we can use to compute probabilities.\n",
    "    for x in X:\n",
    "        relevant_counts = var_to_val_to_count.get(x)\n",
    "        total_count = sum([count for count in relevant_counts.values()])\n",
    "        normalized_distribution = {}\n",
    "        for value, count in relevant_counts.items():\n",
    "            normalized_distribution[value] = count / total_count\n",
    "        print(\"Distribution for \", x, \":\", normalized_distribution)\n",
    "    print(\"Num samples used:\", num_samples - num_rejects)\n",
    "    print(\"Num samples rejected\", num_rejects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for  Feet : {'dry': 0.5102168735113451, 'damp': 0.30036354519242825, 'drenched': 0.18941958129622666}\n",
      "Num samples used: 7977\n",
      "Num samples rejected 2023\n",
      "Distribution for  Rain : {True: 0.2998102466793169, False: 0.7001897533206831}\n",
      "Distribution for  Grass : {'wet': 0.8285895003162556, 'dry': 0.17141049968374447}\n",
      "Num samples used: 1581\n",
      "Num samples rejected 8419\n"
     ]
    }
   ],
   "source": [
    "# Test the rejection sampling code.\n",
    "# First, a really simple example.\n",
    "rejection_sampling(['Feet'], [('Rain', False)], net)\n",
    "# Now, a harder one, with more evidence and asking about more\n",
    "rejection_sampling(['Rain', 'Grass'], [('Sprinklers', 'on'), ('Feet', 'drenched')], net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous example, we saw how rejection sampling can get us the distributions we want, but we also see one of the big flaws: we end up rejecting lots of samples. Lets do gibbs sampling instead!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: this code is ugly, but I do think it's correct.\n",
    "def gibbs_sampling(X, e, net, burn_in_period=100, eval_period=5000):\n",
    "    # For each of the variables in X, store a count of how often each value in the domain appears.\n",
    "    # Intialization to zero counts everywhere.\n",
    "    var_to_val_to_count = {}\n",
    "    for x in X:\n",
    "        var_to_val_to_count[x] = {}\n",
    "        for val in net.get_node(x).domain:\n",
    "            var_to_val_to_count[x][val] = 0\n",
    "    evidence_names = [evidence[0] for evidence in e]\n",
    "    # Intialize the net with random assignments.\n",
    "    assignments = {}\n",
    "    ordered_nodes = net.get_topographical_ordering()\n",
    "    for node in ordered_nodes:\n",
    "        if node.marginal_distribution:\n",
    "            sample = node.draw_sample()\n",
    "            assignments[node] = sample\n",
    "        else:\n",
    "            parent_val_assignments = [(parent, assignments.get(parent)) for parent in node.parents]\n",
    "            sample = node.draw_sample(parent_vals=parent_val_assignments)\n",
    "            assignments[node] = sample\n",
    "    # Now the burn-in section\n",
    "    all_nodes = net.nodes\n",
    "    for trial in range(burn_in_period + eval_period):\n",
    "        # Choose a random node, as long as it's not evidence.\n",
    "        node_to_swap = np.random.choice(all_nodes)\n",
    "        while node_to_swap.name in evidence_names:\n",
    "            node_to_swap = np.random.choice(all_nodes)\n",
    "        # Generate the distribution over next possible values of the node, conditioned on parents and children.\n",
    "        parent_assignments = [(parent, assignments.get(parent)) for parent in node_to_swap.parents]\n",
    "        next_distribution = {}\n",
    "        for next_val in node_to_swap.domain:\n",
    "            prob_given_parents = node_to_swap.get_prob_value(next_val, parent_assignments)\n",
    "            children = net.get_children(node_to_swap)\n",
    "            prob_from_children = 1.0\n",
    "            for child in children:\n",
    "                childs_parent_assignments = []\n",
    "                # But overwrite with next_val\n",
    "                for parent in child.parents:\n",
    "                    if parent == node_to_swap:\n",
    "                        childs_parent_assignments.append((node_to_swap, next_val))\n",
    "                        continue\n",
    "                    childs_parent_assignments.append((parent, assignments.get(parent)))\n",
    "                prob_of_child = child.get_prob_value(assignments.get(child), childs_parent_assignments)\n",
    "                prob_from_children = prob_from_children * prob_of_child\n",
    "            total_prob = prob_given_parents * prob_from_children\n",
    "            next_distribution[next_val] = total_prob\n",
    "        # Normalize the distribution and then sample.\n",
    "        normalizing_factor = sum(next_distribution.values())\n",
    "        for entry, val in next_distribution.items():\n",
    "            next_distribution[entry] = val / normalizing_factor\n",
    "        values = [entry[0] for entry in sorted(next_distribution.items())]\n",
    "        probabilities = [entry[1] for entry in sorted(next_distribution.items())]\n",
    "        sampled = np.random.choice(values, p=probabilities)\n",
    "        assignments[node_to_swap] = sampled\n",
    "        # If after burn-in, start saving data\n",
    "        if trial <= burn_in_period:\n",
    "            continue\n",
    "        # Save the data.\n",
    "        for assigned_node, assigned_val in assignments.items():\n",
    "            if assigned_node.name in var_to_val_to_count.keys():\n",
    "                var_to_val_to_count[assigned_node.name][assigned_val] += 1\n",
    "    # At the end, finally have counts that we can use to compute probabilities.\n",
    "    for x in X:\n",
    "        relevant_counts = var_to_val_to_count.get(x)\n",
    "        total_count = sum([count for count in relevant_counts.values()])\n",
    "        normalized_distribution = {}\n",
    "        for value, count in relevant_counts.items():\n",
    "            normalized_distribution[value] = count / total_count\n",
    "        print(\"Distribution for \", x, \":\", normalized_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution for  Feet : {'dry': 0.5471094218843768, 'damp': 0.27345469093818764, 'drenched': 0.1794358871774355}\n",
      "\n",
      "Distribution for  Rain : {True: 0.27825565113022604, False: 0.7217443488697739}\n",
      "Distribution for  Grass : {'wet': 0.8195639127825565, 'dry': 0.18043608721744347}\n"
     ]
    }
   ],
   "source": [
    "# Test out Gibbs with the same examples as for rejection sampling\n",
    "gibbs_sampling(['Feet'], [('Rain', False)], net)\n",
    "print()\n",
    "gibbs_sampling(['Rain', 'Grass'], [('Sprinklers', 'on'), ('Feet', 'drenched')], net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
